a.k.a.
## Realtime Audio Classification for Musicians
(As an homage to [Tensorflow for Poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0).)

## Overview 
In this workshop, we will teach you how to design audio classifiers using neural nets. We will guide you through the steps of collecting and organizing data, generating spectrographs, training a network, and the using that network to detect audio in realtime. We will use Jupyter notebooks, Python3, pyTorch, and Librosa to play with neural nets that can detect different music and different audio sources. 

## Provisional Workshop Schedule

| Time | Monday | Tuesdsay | Wednesday | Thursday | Friday |
| ------------- | ------------- |------------- |------------- |------------- |------------- |
| 9am | Introductions  | Review/Q&A | Review/Q&A | Review/Q&A | Review/Q&A |
| 10-noon | Neural Nets  | Collecting & Analyzing Sounds | Designing Interaction | Generative Models | Project time |
| noon-1:30 | Lunch  | Lunch | Lunch  | Lunch  | Lunch  |
|1:30-4:30 | Cats & Dogs Lab | Stanford Sounds Dataset | Urban Sounds Dataset | Final Project | Project Time/ Show and Tell |
|4:30-5pm| Cleanup | Cleanup | Cleanup |Cleanup | Happy Hour |
## Labs

[Lab 0. Setting up](Lab-0.-Setting-up)

[Lab 1. Organizing Data for Learning](Lab-1.-Organizing-Data-for-Learning)

[Lab 2. Pictures of Sounds](Lab-2.-Pictures-of-Sounds)